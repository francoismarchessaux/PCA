{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0741229",
   "metadata": {},
   "source": [
    "# PCA Hedging Project — End-to-End Notebook (Steps 1→4)\n",
    "\n",
    "This notebook runs the full pipeline with **one main builder** and shows diagnostics at each step.\n",
    "\n",
    "**Inputs you need**\n",
    "- Market data table: rows = dates, columns = tenors (e.g. `2Y, 3Y, ...`).\n",
    "- (Optional) Sensitivities by tenor (DV01 per bp) to run the PnL tracking backtest.\n",
    "\n",
    "**Outputs**\n",
    "- Rolling PCA explained variance and loadings\n",
    "- Family A anchors and mapping diagnostics\n",
    "- Family B selected proxy instruments (outrights/spreads/flies)\n",
    "- Backtest metrics: tracking RMSE/MAE/tails\n",
    "\n",
    "> Tip: If you don’t have sensitivities yet, the notebook can generate **synthetic sensitivities** to validate the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# --- Paste the unified pipeline code here (the one we built) ---\n",
    "# You should paste:\n",
    "# 1) Step 1 utilities + build_market_matrices\n",
    "# 2) RollingPCAModel + PCAFitResult\n",
    "# 3) Family A / Family B / Backtest helpers\n",
    "# 4) PCAHedgeOptions + build_pca_hedge_model\n",
    "\n",
    "# After pasting, run this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d48697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 1 — Load Market Data\n",
    "# =========================\n",
    "# Option A: read from a file\n",
    "# - CSV: first column is date index (or set date_col)\n",
    "# - Excel: set sheet_name and date_col if date is a column\n",
    "\n",
    "DATA_MODE = \"path\"   # \"path\" | \"raw_df\" | \"x_changes\"\n",
    "PATH = \"curve_timeseries.csv\"     # <- change\n",
    "SHEET_NAME = None                # for Excel\n",
    "DATE_COL = None                  # e.g. \"Date\" if date is a column\n",
    "INDEX_COL = 0                    # if date is first column\n",
    "\n",
    "# Units:\n",
    "# - input_unit=\"pct\"  means 2.35 is 2.35%\n",
    "# - input_unit=\"dec\"  means 0.0235 is 2.35%\n",
    "# - input_unit=\"bp\"   means 235 is 2.35%\n",
    "UNITS = RateUnits(input_unit=\"pct\", target_unit=\"bp\")\n",
    "\n",
    "# Optional tenor restriction (recommended to stabilize early):\n",
    "# RESTRICT_TENORS = [\"2Y\",\"3Y\",\"5Y\",\"7Y\",\"10Y\",\"15Y\",\"20Y\",\"30Y\"]\n",
    "RESTRICT_TENORS = None\n",
    "\n",
    "opts = PCAHedgeOptions(\n",
    "    data_mode=DATA_MODE,\n",
    "    path=PATH,\n",
    "    sheet_name=SHEET_NAME,\n",
    "    date_col=DATE_COL,\n",
    "    index_col=INDEX_COL,\n",
    "    restrict_tenors=RESTRICT_TENORS,\n",
    "    units=UNITS,\n",
    "\n",
    "    # PCA defaults (edit freely)\n",
    "    n_components=3,\n",
    "    pca_method=\"cov\",\n",
    "    pca_estimator=\"ledoitwolf\",\n",
    "    lookback=\"2Y\",\n",
    "    min_obs=252,\n",
    "\n",
    "    # Families\n",
    "    run_familyA=True,\n",
    "    run_familyB=True,\n",
    "\n",
    "    # Family A: set to fixed anchors first, then try auto\n",
    "    familyA=AnchorSelectionConfig(\n",
    "        anchors_mode=\"fixed\",\n",
    "        fixed_anchors=[\"3Y\",\"5Y\",\"10Y\",\"20Y\"],\n",
    "        k_anchors=4,\n",
    "        ridge_lambda=1e-6,\n",
    "        cond_max=1e4,\n",
    "        min_improvement_to_switch=0.002,\n",
    "    ),\n",
    "\n",
    "    # Family B stability selection (start conservative)\n",
    "    familyB=StabilitySelectionConfig(\n",
    "        n_subsamples=100,\n",
    "        subsample_frac=0.6,\n",
    "        alpha_grid=(0.001, 0.002, 0.005),\n",
    "        l1_ratio=0.9,\n",
    "        select_prob_threshold=0.6,\n",
    "        max_features=1,      # set 2-3 for more robustness\n",
    "        ridge_alpha=1e-6,\n",
    "    ),\n",
    "    familyB_max_spreads=2000,\n",
    "    familyB_max_flies=4000,\n",
    "    familyB_min_tenor_gap=2,\n",
    "    familyB_restrict_by_kind=True,\n",
    "\n",
    "    # Backtest disabled here; we enable after we load sensitivities\n",
    "    run_backtest=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Build model (Steps 1→3)\n",
    "model = build_pca_hedge_model(opts)\n",
    "\n",
    "levels = model.get(\"levels\")      # may be None if data_mode=\"x_changes\"\n",
    "changes = model[\"changes\"]\n",
    "meta = model[\"meta\"]\n",
    "\n",
    "print(\"Meta:\", meta)\n",
    "print(\"Levels shape:\", None if levels is None else levels.shape)\n",
    "print(\"Changes shape:\", changes.shape)\n",
    "\n",
    "display(changes.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# STEP 2 — Rolling PCA\n",
    "# =====================\n",
    "pca_states = model[\"pca_states\"]\n",
    "\n",
    "print(f\"Number of as-of PCA fits: {len(pca_states)}\")\n",
    "last_asof = list(pca_states.keys())[-1]\n",
    "state = pca_states[last_asof]\n",
    "\n",
    "print(\"Last asof:\", last_asof)\n",
    "print(\"Window:\", state.window_start.date(), \"→\", state.window_end.date(), \"n_obs:\", state.n_obs)\n",
    "\n",
    "evr = state.explained_var_ratio\n",
    "display(evr.head(10))\n",
    "\n",
    "print(\"Loadings (first 10 tenors):\")\n",
    "display(state.loadings.head(10))\n",
    "\n",
    "# Quick look at PC1/PC2/PC3 time series in the last window\n",
    "scores = state.scores_in_window\n",
    "display(scores.tail())\n",
    "\n",
    "# Optional plot (matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "scores[\"PC1\"].plot()\n",
    "plt.title(\"PC1 score (last calibration window)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "scores[\"PC2\"].plot()\n",
    "plt.title(\"PC2 score (last calibration window)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "scores[\"PC3\"].plot()\n",
    "plt.title(\"PC3 score (last calibration window)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# STEP 3A — Family A (Anchors)\n",
    "# =============================\n",
    "familyA = model.get(\"familyA\", {})\n",
    "print(\"Family A days:\", len(familyA))\n",
    "\n",
    "if familyA:\n",
    "    lastA = familyA[list(familyA.keys())[-1]]\n",
    "    print(\"Last asof:\", lastA.asof)\n",
    "    print(\"Anchors:\", lastA.anchors)\n",
    "    print(f\"Reconstruction score={lastA.score:.6f} rmse={lastA.rmse:.4f} cond={lastA.cond:.1f}\")\n",
    "\n",
    "    print(\"Mapping B (anchors -> tenors) excerpt:\")\n",
    "    display(lastA.mapping_B.iloc[:, :10])\n",
    "\n",
    "    # Show anchor evolution (how often they change)\n",
    "    anchors_series = pd.Series({d: tuple(v.anchors) for d, v in familyA.items()})\n",
    "    turnover = (anchors_series != anchors_series.shift(1)).sum()\n",
    "    print(f\"Anchor set changes over time: {int(turnover)} (out of {len(anchors_series)})\")\n",
    "\n",
    "    display(anchors_series.tail(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# STEP 3B — Family B (Sparse Proxies)\n",
    "# =====================================\n",
    "familyB = model.get(\"familyB\", {})\n",
    "print(\"Family B days:\", len(familyB))\n",
    "\n",
    "if familyB:\n",
    "    last_date = list(familyB.keys())[-1]\n",
    "    fits = familyB[last_date]\n",
    "    print(\"Last asof:\", last_date)\n",
    "\n",
    "    for pc, fit in fits.items():\n",
    "        print(f\"{pc}: selected={fit.selected}\")\n",
    "        # Show top 10 selection probabilities\n",
    "        display(fit.selection_prob.head(10))\n",
    "\n",
    "    # Track how often selections change (union of selected instruments)\n",
    "    union_sel = pd.Series({\n",
    "        d: tuple(sorted(set(inst for f in day.values() for inst in f.selected)))\n",
    "        for d, day in familyB.items()\n",
    "    })\n",
    "    changes_count = (union_sel != union_sel.shift(1)).sum()\n",
    "    print(f\"Union instrument set changes: {int(changes_count)} (out of {len(union_sel)})\")\n",
    "    display(union_sel.tail(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 4 — Backtest (PnL)\n",
    "# =========================\n",
    "# Provide sensitivities in one of two ways:\n",
    "#   A) sens_by_tenor: DataFrame (dates x tenors)\n",
    "#   B) sens_vec:      Series (tenors)\n",
    "\n",
    "USE_SYNTHETIC_SENS = True\n",
    "\n",
    "if USE_SYNTHETIC_SENS:\n",
    "    # Synthetic book for end-to-end validation (replace once desk sensitivities arrive)\n",
    "    # Concentrated around 10Y, smooth across curve\n",
    "    sens_vec = make_synthetic_sensitivities(changes, center_tenor=\"10Y\", width=2.0, total_risk=1e6)\n",
    "    sens_by_tenor = None\n",
    "else:\n",
    "    # Example: load real sensitivities\n",
    "    # sens_by_tenor = pd.read_csv(\"sensitivities.csv\", index_col=0, parse_dates=True)\n",
    "    # sens_vec = None\n",
    "    sens_by_tenor = None\n",
    "    sens_vec = None\n",
    "\n",
    "# Rebuild model with backtest enabled\n",
    "opts_bt = opts\n",
    "opts_bt.run_backtest = True\n",
    "opts_bt.sens_by_tenor = sens_by_tenor\n",
    "opts_bt.sens_vec = sens_vec\n",
    "opts_bt.backtest = BacktestConfig(lookback=opts.lookback, min_obs=opts.min_obs, ridge_alpha=1e-6)\n",
    "\n",
    "model_bt = build_pca_hedge_model(opts_bt)\n",
    "\n",
    "print(\"Backtest keys:\", [k for k in model_bt.keys() if k.startswith(\"backtest\") or k.startswith(\"stats\")])\n",
    "\n",
    "if \"statsA\" in model_bt:\n",
    "    print(\"Family A stats:\", model_bt[\"statsA\"])\n",
    "if \"statsB\" in model_bt:\n",
    "    print(\"Family B stats:\", model_bt[\"statsB\"])\n",
    "\n",
    "# Plot PnL comparison (if available)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if \"backtestA\" in model_bt:\n",
    "    pnl_full = model_bt[\"backtestA\"][\"pnl_full\"]\n",
    "    pnl_A = model_bt[\"backtestA\"][\"pnl_A\"]\n",
    "\n",
    "    plt.figure()\n",
    "    (pnl_full.cumsum()).plot(label=\"Full\")\n",
    "    (pnl_A.cumsum()).plot(label=\"Family A hedge\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Cumulative PnL: Full vs Family A hedge\")\n",
    "    plt.show()\n",
    "\n",
    "if \"backtestB\" in model_bt:\n",
    "    pnl_full = model_bt[\"backtestB\"][\"pnl_full\"]\n",
    "    pnl_B = model_bt[\"backtestB\"][\"pnl_B\"]\n",
    "\n",
    "    plt.figure()\n",
    "    (pnl_full.cumsum()).plot(label=\"Full\")\n",
    "    (pnl_B.cumsum()).plot(label=\"Family B hedge\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Cumulative PnL: Full vs Family B hedge\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
